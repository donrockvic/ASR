{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-mdzN7C_MA"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmqJtMNSDN4C"
      },
      "source": [
        "dataLabels = ['tree','house','zero','bed','yes','four','up','stop','no','wow','nine','happy','follow', 'visual','cat','two', 'forward', 'down','right', 'marvin', 'seven', 'go', 'three',  'backward', 'on', 'dog', 'one', 'sheila', 'eight', 'bird', 'six', 'learn', 'off', 'left', 'five']\n",
        "file_path='/content/drive/MyDrive/Colab Notebooks/data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFQokaKBSXt"
      },
      "source": [
        "def get_train_test(filepath,labels):\n",
        "    # Getting first arrays\n",
        "    X = np.load(file_path+labels[0]+'.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load(file_path+label + '.npy')\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= 0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee1UeA0NDcqH"
      },
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test(file_path,dataLabels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUNfwbRIDgjn"
      },
      "source": [
        "# # Feature dimension\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "\n",
        "num_classes = 35\n",
        "channels = 1\n",
        "max_len = 44\n",
        "buckets = 20\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], buckets, max_len, channels)\n",
        "X_test = X_test.reshape(X_test.shape[0],  buckets, max_len, channels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "qakSsmwCFPYk",
        "outputId": "7b51c675-60a6-4388-b1bb-f4fbffd14a83"
      },
      "source": [
        "plt.imshow(X_train[100, :, :, 0])\n",
        "print(y_train[100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w3VEgFmFl1t"
      },
      "source": [
        "y_train_hot = to_categorical(y_train,dtype='float32')\n",
        "y_test_hot = to_categorical(y_test,dtype='float32')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zih0cNIDlntv"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], buckets, max_len)\n",
        "X_test = X_test.reshape(X_test.shape[0], buckets, max_len)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EpHKCAxHySR",
        "outputId": "85213ddb-cf0f-47f0-aa55-0a5676dd3ae4"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((84663, 20, 44), (21166, 20, 44))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4YFeCn1F8ZE"
      },
      "source": [
        "# # lr = 0.01\n",
        "# loss: 27.4943 - accuracy: 0.4399 - val_loss: 27.2929 - val_accuracy: 0.4311\n",
        "# loss: 26.3002 - accuracy: 0.4495 - val_loss: 26.3374 - val_accuracy: 0.4521\n",
        "# loss: 1.8144 - accuracy: 0.3435 - val_loss: 1.6906 - val_accuracy: 0.4290\n",
        "# loss: 1.7225 - accuracy: 0.3773 - val_loss: 1.6321 - val_accuracy: 0.4430\n",
        "# loss: 1.5523 - accuracy: 0.4461 - val_loss: 1.4504 - val_accuracy: 0.5420\n",
        "# loss: 1.0734 - accuracy: 0.6404 - val_loss: 1.1595 - val_accuracy: 0.6581\n",
        "# loss: 0.8476 - accuracy: 0.7358 - val_loss: 0.9975 - val_accuracy: 0.7095\n",
        "\n",
        "# epochs 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqct3gfUiwpc"
      },
      "source": [
        "# build model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(buckets, max_len)))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.6))\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.4))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhwonn4_m75R",
        "outputId": "574262f3-e84f-4ca7-d92f-7ca518032a9d"
      },
      "source": [
        "print(model.summary())\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 880)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               225536    \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 35)                4515      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 35)                0         \n",
            "=================================================================\n",
            "Total params: 1,575,971\n",
            "Trainable params: 1,575,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siCzNBRBlL-k",
        "outputId": "c6cc24d0-f801-4931-e580-3a3e6c6272e0"
      },
      "source": [
        "model.fit(X_train,y_train_hot, epochs=100, validation_data=(X_test, y_test_hot))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 3.4431 - accuracy: 0.1698 - val_loss: 1.8907 - val_accuracy: 0.4684\n",
            "Epoch 2/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 2.0866 - accuracy: 0.3842 - val_loss: 1.6264 - val_accuracy: 0.5386\n",
            "Epoch 3/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.8676 - accuracy: 0.4482 - val_loss: 1.4950 - val_accuracy: 0.5772\n",
            "Epoch 4/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.7262 - accuracy: 0.4907 - val_loss: 1.3829 - val_accuracy: 0.6183\n",
            "Epoch 5/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.6478 - accuracy: 0.5158 - val_loss: 1.3609 - val_accuracy: 0.6193\n",
            "Epoch 6/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5812 - accuracy: 0.5331 - val_loss: 1.3018 - val_accuracy: 0.6362\n",
            "Epoch 7/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5352 - accuracy: 0.5493 - val_loss: 1.2209 - val_accuracy: 0.6590\n",
            "Epoch 8/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4957 - accuracy: 0.5613 - val_loss: 1.2143 - val_accuracy: 0.6587\n",
            "Epoch 9/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4734 - accuracy: 0.5705 - val_loss: 1.1867 - val_accuracy: 0.6695\n",
            "Epoch 10/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.4297 - accuracy: 0.5815 - val_loss: 1.1580 - val_accuracy: 0.6754\n",
            "Epoch 11/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.3996 - accuracy: 0.5881 - val_loss: 1.1134 - val_accuracy: 0.6973\n",
            "Epoch 12/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3663 - accuracy: 0.5993 - val_loss: 1.1016 - val_accuracy: 0.6957\n",
            "Epoch 13/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3451 - accuracy: 0.6065 - val_loss: 1.1339 - val_accuracy: 0.6823\n",
            "Epoch 14/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3268 - accuracy: 0.6118 - val_loss: 1.1150 - val_accuracy: 0.6916\n",
            "Epoch 15/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2982 - accuracy: 0.6206 - val_loss: 1.0649 - val_accuracy: 0.6975\n",
            "Epoch 16/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.2862 - accuracy: 0.6268 - val_loss: 1.0225 - val_accuracy: 0.7132\n",
            "Epoch 17/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.2672 - accuracy: 0.6339 - val_loss: 1.0634 - val_accuracy: 0.7135\n",
            "Epoch 18/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2510 - accuracy: 0.6361 - val_loss: 1.0171 - val_accuracy: 0.7140\n",
            "Epoch 19/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2378 - accuracy: 0.6388 - val_loss: 1.0170 - val_accuracy: 0.7196\n",
            "Epoch 20/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2324 - accuracy: 0.6420 - val_loss: 1.0034 - val_accuracy: 0.7196\n",
            "Epoch 21/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2167 - accuracy: 0.6465 - val_loss: 0.9769 - val_accuracy: 0.7237\n",
            "Epoch 22/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2091 - accuracy: 0.6508 - val_loss: 0.9710 - val_accuracy: 0.7232\n",
            "Epoch 23/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1840 - accuracy: 0.6574 - val_loss: 0.9865 - val_accuracy: 0.7224\n",
            "Epoch 24/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1839 - accuracy: 0.6581 - val_loss: 1.0158 - val_accuracy: 0.7125\n",
            "Epoch 25/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1702 - accuracy: 0.6617 - val_loss: 0.9756 - val_accuracy: 0.7261\n",
            "Epoch 26/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1649 - accuracy: 0.6630 - val_loss: 0.9402 - val_accuracy: 0.7340\n",
            "Epoch 27/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1498 - accuracy: 0.6667 - val_loss: 0.9587 - val_accuracy: 0.7392\n",
            "Epoch 28/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1360 - accuracy: 0.6729 - val_loss: 0.9397 - val_accuracy: 0.7401\n",
            "Epoch 29/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1394 - accuracy: 0.6722 - val_loss: 0.9417 - val_accuracy: 0.7358\n",
            "Epoch 30/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1296 - accuracy: 0.6755 - val_loss: 0.9557 - val_accuracy: 0.7342\n",
            "Epoch 31/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1265 - accuracy: 0.6755 - val_loss: 0.9345 - val_accuracy: 0.7481\n",
            "Epoch 32/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1182 - accuracy: 0.6765 - val_loss: 0.9368 - val_accuracy: 0.7436\n",
            "Epoch 33/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1126 - accuracy: 0.6792 - val_loss: 0.9372 - val_accuracy: 0.7399\n",
            "Epoch 34/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1028 - accuracy: 0.6839 - val_loss: 0.9269 - val_accuracy: 0.7448\n",
            "Epoch 35/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0912 - accuracy: 0.6871 - val_loss: 0.9154 - val_accuracy: 0.7440\n",
            "Epoch 36/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0908 - accuracy: 0.6877 - val_loss: 0.9298 - val_accuracy: 0.7432\n",
            "Epoch 37/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0756 - accuracy: 0.6922 - val_loss: 0.9113 - val_accuracy: 0.7423\n",
            "Epoch 38/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0804 - accuracy: 0.6925 - val_loss: 0.9054 - val_accuracy: 0.7440\n",
            "Epoch 39/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0803 - accuracy: 0.6931 - val_loss: 0.9103 - val_accuracy: 0.7479\n",
            "Epoch 40/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0605 - accuracy: 0.6967 - val_loss: 0.9413 - val_accuracy: 0.7444\n",
            "Epoch 41/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0646 - accuracy: 0.6940 - val_loss: 0.9332 - val_accuracy: 0.7442\n",
            "Epoch 42/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0513 - accuracy: 0.7000 - val_loss: 0.9278 - val_accuracy: 0.7479\n",
            "Epoch 43/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0572 - accuracy: 0.6973 - val_loss: 0.9204 - val_accuracy: 0.7461\n",
            "Epoch 44/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0588 - accuracy: 0.6972 - val_loss: 0.8659 - val_accuracy: 0.7588\n",
            "Epoch 45/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0424 - accuracy: 0.7021 - val_loss: 0.8905 - val_accuracy: 0.7601\n",
            "Epoch 46/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0404 - accuracy: 0.7044 - val_loss: 0.8851 - val_accuracy: 0.7493\n",
            "Epoch 47/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0487 - accuracy: 0.7011 - val_loss: 0.9132 - val_accuracy: 0.7471\n",
            "Epoch 48/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0439 - accuracy: 0.7021 - val_loss: 0.9030 - val_accuracy: 0.7476\n",
            "Epoch 49/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0474 - accuracy: 0.7063 - val_loss: 0.8837 - val_accuracy: 0.7575\n",
            "Epoch 50/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0392 - accuracy: 0.7045 - val_loss: 0.9223 - val_accuracy: 0.7413\n",
            "Epoch 51/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0408 - accuracy: 0.7053 - val_loss: 0.9290 - val_accuracy: 0.7456\n",
            "Epoch 52/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0350 - accuracy: 0.7063 - val_loss: 0.9084 - val_accuracy: 0.7455\n",
            "Epoch 53/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0310 - accuracy: 0.7096 - val_loss: 0.8856 - val_accuracy: 0.7571\n",
            "Epoch 54/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0192 - accuracy: 0.7112 - val_loss: 0.9131 - val_accuracy: 0.7455\n",
            "Epoch 55/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0086 - accuracy: 0.7127 - val_loss: 0.8871 - val_accuracy: 0.7594\n",
            "Epoch 56/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.0089 - accuracy: 0.7146 - val_loss: 0.8694 - val_accuracy: 0.7612\n",
            "Epoch 57/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0186 - accuracy: 0.7127 - val_loss: 0.8827 - val_accuracy: 0.7534\n",
            "Epoch 58/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0116 - accuracy: 0.7142 - val_loss: 0.8753 - val_accuracy: 0.7577\n",
            "Epoch 59/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.0046 - accuracy: 0.7158 - val_loss: 0.8650 - val_accuracy: 0.7674\n",
            "Epoch 60/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9946 - accuracy: 0.7188 - val_loss: 0.8698 - val_accuracy: 0.7621\n",
            "Epoch 61/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 0.9967 - accuracy: 0.7196 - val_loss: 0.8654 - val_accuracy: 0.7583\n",
            "Epoch 62/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9911 - accuracy: 0.7199 - val_loss: 0.8722 - val_accuracy: 0.7579\n",
            "Epoch 63/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9774 - accuracy: 0.7211 - val_loss: 0.8652 - val_accuracy: 0.7643\n",
            "Epoch 64/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9765 - accuracy: 0.7235 - val_loss: 0.8923 - val_accuracy: 0.7545\n",
            "Epoch 65/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9947 - accuracy: 0.7202 - val_loss: 0.8874 - val_accuracy: 0.7533\n",
            "Epoch 66/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9831 - accuracy: 0.7239 - val_loss: 0.8649 - val_accuracy: 0.7594\n",
            "Epoch 67/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 0.9854 - accuracy: 0.7216 - val_loss: 0.8630 - val_accuracy: 0.7616\n",
            "Epoch 68/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9891 - accuracy: 0.7217 - val_loss: 0.8723 - val_accuracy: 0.7594\n",
            "Epoch 69/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9692 - accuracy: 0.7279 - val_loss: 0.8708 - val_accuracy: 0.7576\n",
            "Epoch 70/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9900 - accuracy: 0.7221 - val_loss: 0.9022 - val_accuracy: 0.7501\n",
            "Epoch 71/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 0.9829 - accuracy: 0.7236 - val_loss: 0.8445 - val_accuracy: 0.7638\n",
            "Epoch 72/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9814 - accuracy: 0.7257 - val_loss: 0.8395 - val_accuracy: 0.7667\n",
            "Epoch 73/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9819 - accuracy: 0.7232 - val_loss: 0.8918 - val_accuracy: 0.7517\n",
            "Epoch 74/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9781 - accuracy: 0.7248 - val_loss: 0.8314 - val_accuracy: 0.7697\n",
            "Epoch 75/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9704 - accuracy: 0.7284 - val_loss: 0.8689 - val_accuracy: 0.7618\n",
            "Epoch 76/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9657 - accuracy: 0.7300 - val_loss: 0.8839 - val_accuracy: 0.7535\n",
            "Epoch 77/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9698 - accuracy: 0.7303 - val_loss: 0.9012 - val_accuracy: 0.7544\n",
            "Epoch 78/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9674 - accuracy: 0.7275 - val_loss: 0.8446 - val_accuracy: 0.7662\n",
            "Epoch 79/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9603 - accuracy: 0.7315 - val_loss: 0.8680 - val_accuracy: 0.7645\n",
            "Epoch 80/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9717 - accuracy: 0.7275 - val_loss: 0.8604 - val_accuracy: 0.7676\n",
            "Epoch 81/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9617 - accuracy: 0.7296 - val_loss: 0.8773 - val_accuracy: 0.7642\n",
            "Epoch 82/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 0.9493 - accuracy: 0.7313 - val_loss: 0.8564 - val_accuracy: 0.7666\n",
            "Epoch 83/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9661 - accuracy: 0.7303 - val_loss: 0.8616 - val_accuracy: 0.7639\n",
            "Epoch 84/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9567 - accuracy: 0.7332 - val_loss: 0.8265 - val_accuracy: 0.7771\n",
            "Epoch 85/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9363 - accuracy: 0.7358 - val_loss: 0.8602 - val_accuracy: 0.7690\n",
            "Epoch 86/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9636 - accuracy: 0.7316 - val_loss: 0.8598 - val_accuracy: 0.7603\n",
            "Epoch 87/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9474 - accuracy: 0.7352 - val_loss: 0.8835 - val_accuracy: 0.7519\n",
            "Epoch 88/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9533 - accuracy: 0.7337 - val_loss: 0.8414 - val_accuracy: 0.7705\n",
            "Epoch 89/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9435 - accuracy: 0.7376 - val_loss: 0.8602 - val_accuracy: 0.7669\n",
            "Epoch 90/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9508 - accuracy: 0.7354 - val_loss: 0.9146 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9407 - accuracy: 0.7387 - val_loss: 0.9020 - val_accuracy: 0.7528\n",
            "Epoch 92/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9460 - accuracy: 0.7366 - val_loss: 0.8418 - val_accuracy: 0.7706\n",
            "Epoch 93/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9462 - accuracy: 0.7372 - val_loss: 0.8290 - val_accuracy: 0.7736\n",
            "Epoch 94/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9313 - accuracy: 0.7399 - val_loss: 0.8642 - val_accuracy: 0.7662\n",
            "Epoch 95/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9320 - accuracy: 0.7410 - val_loss: 0.8267 - val_accuracy: 0.7748\n",
            "Epoch 96/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 0.9558 - accuracy: 0.7342 - val_loss: 0.8117 - val_accuracy: 0.7799\n",
            "Epoch 97/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9374 - accuracy: 0.7392 - val_loss: 0.8355 - val_accuracy: 0.7701\n",
            "Epoch 98/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9311 - accuracy: 0.7387 - val_loss: 0.8519 - val_accuracy: 0.7713\n",
            "Epoch 99/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9353 - accuracy: 0.7415 - val_loss: 0.8956 - val_accuracy: 0.7597\n",
            "Epoch 100/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 0.9303 - accuracy: 0.7407 - val_loss: 0.8464 - val_accuracy: 0.7622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1b0339908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvaIQ4T7l-5X"
      },
      "source": [
        "model.save(\"my_h5_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6hBqa5KZYXM"
      },
      "source": [
        "! cp my_h5_model.h5 '/content/drive/MyDrive/Colab Notebooks/data/'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}