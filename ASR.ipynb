{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3waeCc1-L3m"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-mdzN7C_MA"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmqJtMNSDN4C"
      },
      "source": [
        "dataLabels = ['tree','house','zero','bed','yes','four','up','stop','no','wow','nine','happy','follow', 'visual','cat','two', 'forward', 'down','right', 'marvin', 'seven', 'go', 'three',  'backward', 'on', 'dog', 'one', 'sheila', 'eight', 'bird', 'six', 'learn', 'off', 'left', 'five']\n",
        "file_path='/content/drive/MyDrive/Colab Notebooks/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFQokaKBSXt"
      },
      "source": [
        "def get_train_test(filepath,labels):\n",
        "    # Getting first arrays\n",
        "    X = np.load(file_path+labels[0]+'.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load(file_path+label + '.npy')\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= 0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee1UeA0NDcqH"
      },
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test(file_path,dataLabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUNfwbRIDgjn"
      },
      "source": [
        "# # Feature dimension\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "\n",
        "num_classes = 35\n",
        "channels = 1\n",
        "max_len = 44\n",
        "buckets = 20\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], buckets, max_len, channels)\n",
        "X_test = X_test.reshape(X_test.shape[0],  buckets, max_len, channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "qakSsmwCFPYk",
        "outputId": "57650ba0-30ba-480e-febb-b21c7ab4eb5d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_train[100, :, :, 0])\n",
        "print(y_train[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w3VEgFmFl1t"
      },
      "source": [
        "y_train_hot = tf.keras.utils.to_categorical(y_train,dtype='float32')\n",
        "y_test_hot = tf.keras.utils.to_categorical(y_test,dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zih0cNIDlntv"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], buckets, max_len)\n",
        "X_test = X_test.reshape(X_test.shape[0], buckets, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EpHKCAxHySR",
        "outputId": "a7b9840e-f9e3-4cf0-b749-f01e03fadc62"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((84663, 20, 44), (21166, 20, 44))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4YFeCn1F8ZE"
      },
      "source": [
        "# # lr = 0.01\n",
        "# loss: 27.4943 - accuracy: 0.4399 - val_loss: 27.2929 - val_accuracy: 0.4311\n",
        "# loss: 26.3002 - accuracy: 0.4495 - val_loss: 26.3374 - val_accuracy: 0.4521\n",
        "# loss: 1.8144 - accuracy: 0.3435 - val_loss: 1.6906 - val_accuracy: 0.4290\n",
        "# loss: 1.7225 - accuracy: 0.3773 - val_loss: 1.6321 - val_accuracy: 0.4430\n",
        "# loss: 1.5523 - accuracy: 0.4461 - val_loss: 1.4504 - val_accuracy: 0.5420\n",
        "# loss: 1.0734 - accuracy: 0.6404 - val_loss: 1.1595 - val_accuracy: 0.6581\n",
        "# loss: 0.8476 - accuracy: 0.7358 - val_loss: 0.9975 - val_accuracy: 0.7095\n",
        "\n",
        "# epochs 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqct3gfUiwpc"
      },
      "source": [
        "# Define Sequential model with 3 layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Flatten(input_shape=(buckets, max_len)),\n",
        "        layers.Dense(256, activation=\"relu\", name=\"layer1\"),\n",
        "        layers.Dropout(0.6),\n",
        "        layers.Dense(512, activation=\"relu\", name=\"layer2\"),\n",
        "        # layers.Dropout(0.6),\n",
        "        layers.Dense(1024, activation=\"relu\", name=\"layer3\"),\n",
        "        layers.Dense(512, activation=\"relu\", name=\"layer4\"),\n",
        "        layers.Dense(256, activation=\"relu\", name=\"layer5\"),\n",
        "        # layers.Dropout(0.4),\n",
        "        layers.Dense(128, activation=\"relu\", name=\"layer6\"),\n",
        "        layers.Dense(num_classes, activation=\"softmax\", name=\"layer7\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhwonn4_m75R",
        "outputId": "c6c78ea3-ad64-49a8-a0b6-f872f84be573"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 880)               0         \n",
            "_________________________________________________________________\n",
            "layer1 (Dense)               (None, 256)               225536    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "layer4 (Dense)               (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "layer5 (Dense)               (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "layer6 (Dense)               (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "layer7 (Dense)               (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 1,575,971\n",
            "Trainable params: 1,575,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siCzNBRBlL-k",
        "outputId": "4b8cb979-d96b-427a-ac5f-585b35433571"
      },
      "source": [
        "model.fit(X_train, y_train_hot, epochs=100, validation_data=(X_test, y_test_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2646/2646 [==============================] - 10s 3ms/step - loss: 3.6788 - accuracy: 0.1348 - val_loss: 2.1496 - val_accuracy: 0.4002\n",
            "Epoch 2/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 2.3056 - accuracy: 0.3175 - val_loss: 1.8965 - val_accuracy: 0.4860\n",
            "Epoch 3/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 2.0877 - accuracy: 0.3831 - val_loss: 1.7077 - val_accuracy: 0.5162\n",
            "Epoch 4/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.9571 - accuracy: 0.4154 - val_loss: 1.6806 - val_accuracy: 0.5348\n",
            "Epoch 5/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.8749 - accuracy: 0.4425 - val_loss: 1.5684 - val_accuracy: 0.5775\n",
            "Epoch 6/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.8160 - accuracy: 0.4626 - val_loss: 1.5436 - val_accuracy: 0.5705\n",
            "Epoch 7/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.7610 - accuracy: 0.4761 - val_loss: 1.4852 - val_accuracy: 0.5882\n",
            "Epoch 8/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.7225 - accuracy: 0.4919 - val_loss: 1.4664 - val_accuracy: 0.5985\n",
            "Epoch 9/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.6671 - accuracy: 0.5065 - val_loss: 1.4448 - val_accuracy: 0.6085\n",
            "Epoch 10/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.6354 - accuracy: 0.5164 - val_loss: 1.3975 - val_accuracy: 0.6098\n",
            "Epoch 11/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.6049 - accuracy: 0.5229 - val_loss: 1.3754 - val_accuracy: 0.6226\n",
            "Epoch 12/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5911 - accuracy: 0.5281 - val_loss: 1.3094 - val_accuracy: 0.6419\n",
            "Epoch 13/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5556 - accuracy: 0.5395 - val_loss: 1.3437 - val_accuracy: 0.6313\n",
            "Epoch 14/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5159 - accuracy: 0.5534 - val_loss: 1.3250 - val_accuracy: 0.6373\n",
            "Epoch 15/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5176 - accuracy: 0.5540 - val_loss: 1.3687 - val_accuracy: 0.6123\n",
            "Epoch 16/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.5004 - accuracy: 0.5574 - val_loss: 1.3086 - val_accuracy: 0.6351\n",
            "Epoch 17/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4742 - accuracy: 0.5665 - val_loss: 1.2990 - val_accuracy: 0.6424\n",
            "Epoch 18/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4641 - accuracy: 0.5691 - val_loss: 1.2493 - val_accuracy: 0.6569\n",
            "Epoch 19/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4502 - accuracy: 0.5720 - val_loss: 1.2373 - val_accuracy: 0.6617\n",
            "Epoch 20/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4253 - accuracy: 0.5854 - val_loss: 1.2389 - val_accuracy: 0.6544\n",
            "Epoch 21/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4175 - accuracy: 0.5822 - val_loss: 1.2100 - val_accuracy: 0.6653\n",
            "Epoch 22/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.4050 - accuracy: 0.5879 - val_loss: 1.1863 - val_accuracy: 0.6767\n",
            "Epoch 23/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3956 - accuracy: 0.5900 - val_loss: 1.2601 - val_accuracy: 0.6600\n",
            "Epoch 24/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3852 - accuracy: 0.5960 - val_loss: 1.1908 - val_accuracy: 0.6699\n",
            "Epoch 25/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3765 - accuracy: 0.5978 - val_loss: 1.2096 - val_accuracy: 0.6751\n",
            "Epoch 26/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3568 - accuracy: 0.6047 - val_loss: 1.1761 - val_accuracy: 0.6778\n",
            "Epoch 27/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3523 - accuracy: 0.6036 - val_loss: 1.1452 - val_accuracy: 0.6852\n",
            "Epoch 28/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3439 - accuracy: 0.6069 - val_loss: 1.1677 - val_accuracy: 0.6831\n",
            "Epoch 29/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3375 - accuracy: 0.6090 - val_loss: 1.1719 - val_accuracy: 0.6769\n",
            "Epoch 30/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.3192 - accuracy: 0.6142 - val_loss: 1.1447 - val_accuracy: 0.6772\n",
            "Epoch 31/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3199 - accuracy: 0.6167 - val_loss: 1.1411 - val_accuracy: 0.6801\n",
            "Epoch 32/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3093 - accuracy: 0.6201 - val_loss: 1.1163 - val_accuracy: 0.6880\n",
            "Epoch 33/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3002 - accuracy: 0.6206 - val_loss: 1.1375 - val_accuracy: 0.6859\n",
            "Epoch 34/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.3013 - accuracy: 0.6238 - val_loss: 1.1592 - val_accuracy: 0.6892\n",
            "Epoch 35/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2931 - accuracy: 0.6240 - val_loss: 1.1456 - val_accuracy: 0.6938\n",
            "Epoch 36/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2846 - accuracy: 0.6267 - val_loss: 1.1613 - val_accuracy: 0.6935\n",
            "Epoch 37/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2966 - accuracy: 0.6226 - val_loss: 1.1780 - val_accuracy: 0.6804\n",
            "Epoch 38/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2828 - accuracy: 0.6269 - val_loss: 1.1350 - val_accuracy: 0.6964\n",
            "Epoch 39/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2716 - accuracy: 0.6319 - val_loss: 1.1308 - val_accuracy: 0.6921\n",
            "Epoch 40/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2817 - accuracy: 0.6278 - val_loss: 1.1386 - val_accuracy: 0.6820\n",
            "Epoch 41/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2688 - accuracy: 0.6337 - val_loss: 1.1761 - val_accuracy: 0.6878\n",
            "Epoch 42/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2580 - accuracy: 0.6362 - val_loss: 1.1130 - val_accuracy: 0.6987\n",
            "Epoch 43/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2494 - accuracy: 0.6347 - val_loss: 1.1478 - val_accuracy: 0.6909\n",
            "Epoch 44/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2503 - accuracy: 0.6398 - val_loss: 1.1078 - val_accuracy: 0.7027\n",
            "Epoch 45/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2455 - accuracy: 0.6392 - val_loss: 1.0848 - val_accuracy: 0.7092\n",
            "Epoch 46/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2330 - accuracy: 0.6419 - val_loss: 1.1279 - val_accuracy: 0.7045\n",
            "Epoch 47/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2470 - accuracy: 0.6423 - val_loss: 1.1261 - val_accuracy: 0.6968\n",
            "Epoch 48/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2501 - accuracy: 0.6402 - val_loss: 1.0984 - val_accuracy: 0.7091\n",
            "Epoch 49/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2400 - accuracy: 0.6446 - val_loss: 1.1827 - val_accuracy: 0.6868\n",
            "Epoch 50/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2259 - accuracy: 0.6447 - val_loss: 1.1391 - val_accuracy: 0.6887\n",
            "Epoch 51/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2203 - accuracy: 0.6474 - val_loss: 1.1044 - val_accuracy: 0.7014\n",
            "Epoch 52/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2316 - accuracy: 0.6455 - val_loss: 1.1061 - val_accuracy: 0.6961\n",
            "Epoch 53/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2137 - accuracy: 0.6509 - val_loss: 1.0941 - val_accuracy: 0.7096\n",
            "Epoch 54/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2159 - accuracy: 0.6506 - val_loss: 1.1183 - val_accuracy: 0.6958\n",
            "Epoch 55/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2158 - accuracy: 0.6527 - val_loss: 1.1248 - val_accuracy: 0.6955\n",
            "Epoch 56/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2027 - accuracy: 0.6533 - val_loss: 1.0994 - val_accuracy: 0.7054\n",
            "Epoch 57/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1942 - accuracy: 0.6553 - val_loss: 1.0860 - val_accuracy: 0.7064\n",
            "Epoch 58/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1952 - accuracy: 0.6564 - val_loss: 1.0530 - val_accuracy: 0.7215\n",
            "Epoch 59/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2116 - accuracy: 0.6510 - val_loss: 1.1350 - val_accuracy: 0.6837\n",
            "Epoch 60/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.2000 - accuracy: 0.6577 - val_loss: 1.1390 - val_accuracy: 0.7056\n",
            "Epoch 61/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1901 - accuracy: 0.6577 - val_loss: 1.0526 - val_accuracy: 0.7157\n",
            "Epoch 62/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1896 - accuracy: 0.6579 - val_loss: 1.0883 - val_accuracy: 0.7132\n",
            "Epoch 63/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1928 - accuracy: 0.6556 - val_loss: 1.1180 - val_accuracy: 0.6914\n",
            "Epoch 64/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1847 - accuracy: 0.6585 - val_loss: 1.0831 - val_accuracy: 0.7034\n",
            "Epoch 65/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1818 - accuracy: 0.6594 - val_loss: 1.1196 - val_accuracy: 0.7007\n",
            "Epoch 66/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1820 - accuracy: 0.6617 - val_loss: 1.0812 - val_accuracy: 0.7007\n",
            "Epoch 67/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1793 - accuracy: 0.6636 - val_loss: 1.1048 - val_accuracy: 0.7025\n",
            "Epoch 68/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1756 - accuracy: 0.6623 - val_loss: 1.0954 - val_accuracy: 0.7058\n",
            "Epoch 69/100\n",
            "2646/2646 [==============================] - 9s 3ms/step - loss: 1.1709 - accuracy: 0.6652 - val_loss: 1.0635 - val_accuracy: 0.7129\n",
            "Epoch 70/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1702 - accuracy: 0.6666 - val_loss: 1.0647 - val_accuracy: 0.7076\n",
            "Epoch 71/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1706 - accuracy: 0.6653 - val_loss: 1.0808 - val_accuracy: 0.7065\n",
            "Epoch 72/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1745 - accuracy: 0.6647 - val_loss: 1.0692 - val_accuracy: 0.7125\n",
            "Epoch 73/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1763 - accuracy: 0.6643 - val_loss: 1.1197 - val_accuracy: 0.6970\n",
            "Epoch 74/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1647 - accuracy: 0.6664 - val_loss: 1.0845 - val_accuracy: 0.7044\n",
            "Epoch 75/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1573 - accuracy: 0.6677 - val_loss: 1.0580 - val_accuracy: 0.7133\n",
            "Epoch 76/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1637 - accuracy: 0.6682 - val_loss: 1.1082 - val_accuracy: 0.6992\n",
            "Epoch 77/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1592 - accuracy: 0.6700 - val_loss: 1.0861 - val_accuracy: 0.7134\n",
            "Epoch 78/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1637 - accuracy: 0.6676 - val_loss: 1.1342 - val_accuracy: 0.7060\n",
            "Epoch 79/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1618 - accuracy: 0.6703 - val_loss: 1.0643 - val_accuracy: 0.7243\n",
            "Epoch 80/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1582 - accuracy: 0.6701 - val_loss: 1.0782 - val_accuracy: 0.7078\n",
            "Epoch 81/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1501 - accuracy: 0.6718 - val_loss: 1.0790 - val_accuracy: 0.7169\n",
            "Epoch 82/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1575 - accuracy: 0.6708 - val_loss: 1.0711 - val_accuracy: 0.7172\n",
            "Epoch 83/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1479 - accuracy: 0.6729 - val_loss: 1.0873 - val_accuracy: 0.7115\n",
            "Epoch 84/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1527 - accuracy: 0.6752 - val_loss: 1.1161 - val_accuracy: 0.6986\n",
            "Epoch 85/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1596 - accuracy: 0.6686 - val_loss: 1.1099 - val_accuracy: 0.7112\n",
            "Epoch 86/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1469 - accuracy: 0.6749 - val_loss: 1.0911 - val_accuracy: 0.7118\n",
            "Epoch 87/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1670 - accuracy: 0.6707 - val_loss: 1.0835 - val_accuracy: 0.7055\n",
            "Epoch 88/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1585 - accuracy: 0.6728 - val_loss: 1.0577 - val_accuracy: 0.7219\n",
            "Epoch 89/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1547 - accuracy: 0.6707 - val_loss: 1.1046 - val_accuracy: 0.7028\n",
            "Epoch 90/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1413 - accuracy: 0.6729 - val_loss: 1.0679 - val_accuracy: 0.7137\n",
            "Epoch 91/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1491 - accuracy: 0.6732 - val_loss: 1.0668 - val_accuracy: 0.7170\n",
            "Epoch 92/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1503 - accuracy: 0.6734 - val_loss: 1.0704 - val_accuracy: 0.7140\n",
            "Epoch 93/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1479 - accuracy: 0.6739 - val_loss: 1.0873 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1569 - accuracy: 0.6712 - val_loss: 1.0880 - val_accuracy: 0.7116\n",
            "Epoch 95/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1495 - accuracy: 0.6738 - val_loss: 1.0589 - val_accuracy: 0.7127\n",
            "Epoch 96/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1580 - accuracy: 0.6734 - val_loss: 1.0511 - val_accuracy: 0.7134\n",
            "Epoch 97/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1607 - accuracy: 0.6710 - val_loss: 1.1082 - val_accuracy: 0.7071\n",
            "Epoch 98/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1672 - accuracy: 0.6697 - val_loss: 1.0805 - val_accuracy: 0.7108\n",
            "Epoch 99/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1400 - accuracy: 0.6747 - val_loss: 1.0543 - val_accuracy: 0.7123\n",
            "Epoch 100/100\n",
            "2646/2646 [==============================] - 8s 3ms/step - loss: 1.1389 - accuracy: 0.6762 - val_loss: 1.0847 - val_accuracy: 0.7112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f633e5e54e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvaIQ4T7l-5X"
      },
      "source": [
        "model.save(\"my_h5_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6hBqa5KZYXM"
      },
      "source": [
        "! cp my_h5_model.h5 '/content/drive/MyDrive/Colab Notebooks/data/'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}